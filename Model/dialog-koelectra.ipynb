{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b1e377f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, ElectraTokenizer, BertForSequenceClassification, ElectraForSequenceClassification\n",
    "from tqdm.notebook import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea873e24",
   "metadata": {},
   "source": [
    "# dialog-koelectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce0a3286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import ElectraTokenizer, ElectraForSequenceClassification, AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e3bc462",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('/aiffel/aiffel/dktc/train3.csv')\n",
    "test=pd.read_json('/aiffel/aiffel/dktc/data/test.json').transpose()\n",
    "submission = pd.read_csv('/aiffel/aiffel/dktc/data/new_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f21e1520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^가-힣a-z\\s]', ' ', text)\n",
    "    \n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    # 한국어 불용어 리스트\n",
    "    stopwords = [\n",
    "        '이', '있', '하', '것', '들', '그', '되', '수', '이', '보', '않', '없', '나', '사람', '주', '아니', \n",
    "        '등', '같', '우리', '때', '년', '가', '한', '지', '대하', '오', '말', '일', '그렇', '위하', \n",
    "        '때문', '그것', '두', '말하', '알', '그러나', '받', '못하', '일', '그런', '또', '문제', '더', '사회', \n",
    "        '많', '그리고', '좋', '크', '따르', '중', '나오', '가지', '씨', '시키', '만들', '지금', '생각하', \n",
    "        '그러', '속', '하나', '집', '살', '모르', '적', '월', '데', '자신', '안', '어떤', '내', '내', '경우',\n",
    "        '명', '생각', '시간', '그녀', '다시', '이런', '앞', '보이', '번', '나', '다른', '어떻', '여자', '개',\n",
    "        '전', '들', '사실', '이렇', '점', '싶', '말', '정도', '좀', '원', '잘', '통하', '소리', '놓'\n",
    "    ]\n",
    "    \n",
    "    # 불용어 제거\n",
    "    text = ' '.join(word for word in text.split() if word not in stopwords)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2aa2428",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['conversation'] = train['conversation'].apply(clean_text)\n",
    "test['text'] = test['text'].apply(clean_text)\n",
    "\n",
    "#label encoding\n",
    "label_dict = {\n",
    "    '협박 대화': 0,\n",
    "    '갈취 대화': 1,\n",
    "    '직장 내 괴롭힘 대화': 2,\n",
    "    '기타 괴롭힘 대화': 3,\n",
    "    '일반 대화':4\n",
    "}\n",
    "train['label_encoded'] = train['class'].map(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0cc2b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train[['conversation','label_encoded']]\n",
    "train=train.rename(columns={'label_encoded':'class'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a48a321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>당장 뉴스 기사 내가 불러준 대로 보도 해 팩트 체크가 되지 않은 기사는 낼 없습니...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>버러지 같은게 너 내가 누군줄알아 손님 욕하시면 안됩니다 어디서 말대꾸야 미친년이 ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>공책 돌려받길 원하면 빨리 뛰어봐 굼벵아 빨리 내놔 빨릐 내놔아 빨리 내놓으래 웃기...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>사장님 저기 말할게 있는데요 뭔데 임마 게임회사는 전체이용가 게임이잖아요 그래서 그...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>죽고 싶어서 환장했어 왜 이렇게 말을 들어 죄송해요 번만 봐주세요 시키는 대로 하라...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4901</th>\n",
       "      <td>이대리는 남자친구 있나 네 네 있습니다 아 진짜 어떻게 네 그냥 학교에서 만났어요 ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4902</th>\n",
       "      <td>새로 나온 책 읽어봤어 응 정말 재밌었어 내용이야 미스터리 소설인데 반전이 많아 새...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4903</th>\n",
       "      <td>어이 너희 어딘지 이제 아는데 선생님 제발 집에는 오지 마세요 그럼 내가 얘기한 거...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4904</th>\n",
       "      <td>니가 연락 안받는다고 내가 못찾을 줄 알았어 일부러 안받은건 아니었습니다 죄송합니다...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4905</th>\n",
       "      <td>이번 주말에 여행 갈까 어디로 해변으로 가고 싶어 좋아 그럼 계획 세워보자 이번 주...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4906 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           conversation  class\n",
       "0     당장 뉴스 기사 내가 불러준 대로 보도 해 팩트 체크가 되지 않은 기사는 낼 없습니...      0\n",
       "1     버러지 같은게 너 내가 누군줄알아 손님 욕하시면 안됩니다 어디서 말대꾸야 미친년이 ...      3\n",
       "2     공책 돌려받길 원하면 빨리 뛰어봐 굼벵아 빨리 내놔 빨릐 내놔아 빨리 내놓으래 웃기...      3\n",
       "3     사장님 저기 말할게 있는데요 뭔데 임마 게임회사는 전체이용가 게임이잖아요 그래서 그...      2\n",
       "4     죽고 싶어서 환장했어 왜 이렇게 말을 들어 죄송해요 번만 봐주세요 시키는 대로 하라...      0\n",
       "...                                                 ...    ...\n",
       "4901  이대리는 남자친구 있나 네 네 있습니다 아 진짜 어떻게 네 그냥 학교에서 만났어요 ...      2\n",
       "4902  새로 나온 책 읽어봤어 응 정말 재밌었어 내용이야 미스터리 소설인데 반전이 많아 새...      4\n",
       "4903  어이 너희 어딘지 이제 아는데 선생님 제발 집에는 오지 마세요 그럼 내가 얘기한 거...      0\n",
       "4904  니가 연락 안받는다고 내가 못찾을 줄 알았어 일부러 안받은건 아니었습니다 죄송합니다...      0\n",
       "4905  이번 주말에 여행 갈까 어디로 해변으로 가고 싶어 좋아 그럼 계획 세워보자 이번 주...      4\n",
       "\n",
       "[4906 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88daefee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, valid data 분리\n",
    "train_df, val_df = train_test_split(train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66184ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at skplanet/dialog-koelectra-small-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import ElectraTokenizer, ElectraForSequenceClassification\n",
    "  \n",
    "tokenizer = ElectraTokenizer.from_pretrained(\"skplanet/dialog-koelectra-small-discriminator\")\n",
    "\n",
    "model = ElectraForSequenceClassification.from_pretrained(\"skplanet/dialog-koelectra-small-discriminator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e515692e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=128, is_test=False):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.is_test = is_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        if not self.is_test:\n",
    "            conversation = str(self.data.iloc[index]['conversation'])\n",
    "            label = self.data.iloc[index]['class']\n",
    "        else:\n",
    "            conversation = str(self.data.iloc[index]['text'])\n",
    "            label = None\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            conversation,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length' if not self.is_test else 'max_length',  # 테스트 데이터셋도 padding 적용\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        if not self.is_test:\n",
    "            return {\n",
    "                'input_ids': encoding['input_ids'].flatten(),\n",
    "                'attention_mask': encoding['attention_mask'].flatten(),\n",
    "                'labels': torch.tensor(label, dtype=torch.long)\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'input_ids': encoding['input_ids'].flatten(),\n",
    "                'attention_mask': encoding['attention_mask'].flatten()\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea5dd908",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_df, tokenizer,max_length=128,is_test=False)\n",
    "val_dataset = CustomDataset(val_df, tokenizer,max_length=128,is_test=False)\n",
    "\n",
    "test_dataset = CustomDataset(test, tokenizer, max_length=128, is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "838fee1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at skplanet/dialog-koelectra-small-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(40000, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(128, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (embeddings_project): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (activation): GELUActivation()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=256, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ElectraForSequenceClassification.from_pretrained(\"skplanet/dialog-koelectra-small-discriminator\", num_labels=5)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a546514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "batch_size = 16\n",
    "epochs = 3\n",
    "learning_rate = 2e-5\n",
    "\n",
    "# 옵티마이저 및 스케줄러 설정\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataset) * epochs)\n",
    "\n",
    "# 데이터로더 설정\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "# 손실 함수 정의\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7d98480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 1.2209652659854269, Val Accuracy: 0.8256048387096774\n",
      "Epoch 2/3, Train Loss: 0.5569019668349405, Val Accuracy: 0.8991935483870968\n",
      "Epoch 3/3, Train Loss: 0.28300675789151736, Val Accuracy: 0.9143145161290323\n"
     ]
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_accuracy = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            _, predictions = torch.max(logits, dim=1)\n",
    "            val_accuracy += accuracy_score(predictions.cpu().numpy(), labels.cpu().numpy())\n",
    "    \n",
    "    print(f'Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss / len(train_loader)}, Val Accuracy: {val_accuracy / len(val_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ae77311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_001</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_002</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_003</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_004</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>t_005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>t_006</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>t_007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>t_008</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>t_009</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  file_name  class\n",
       "0     t_000      1\n",
       "1     t_001      2\n",
       "2     t_002      2\n",
       "3     t_003      3\n",
       "4     t_004      3\n",
       "5     t_005      0\n",
       "6     t_006      2\n",
       "7     t_007      1\n",
       "8     t_008      3\n",
       "9     t_009      1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        _, batch_predictions = torch.max(logits, dim=1)\n",
    "        predictions.extend(batch_predictions.cpu().numpy())\n",
    "\n",
    "# Submission \n",
    "submission['class']=predictions\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "544badd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission_dialogKobert2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7888b3fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>t_221</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    file_name  class\n",
       "221     t_221      4"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[submission['class']==4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56013b37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
