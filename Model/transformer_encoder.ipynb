{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b86a4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "650307d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from konlpy.tag import Mecab\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,  ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import *\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import *\n",
    "import tensorflow.keras.backend as K\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dc3d49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^가-힣a-z\\s]', ' ', text)\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e963998a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = pd.read_csv('/content/drive/MyDrive/DLthon_data/train3.csv')\n",
    "#test = pd.read_json('/content/drive/MyDrive/DLthon_data/test.json').transpose()\n",
    "#submission = pd.read_csv('/content/drive/MyDrive/DLthon_data/new_submission.csv')\n",
    "\n",
    "train = pd.read_csv('/aiffel/aiffel/dktc/train3.csv')\n",
    "Test = pd.read_json('/aiffel/aiffel/dktc/data/test.json').transpose()\n",
    "submission = pd.read_csv('/aiffel/aiffel/dktc/data/new_submission.csv')\n",
    "\n",
    "label_dict = {\n",
    "    '협박 대화': 0,\n",
    "    '갈취 대화': 1,\n",
    "    '직장 내 괴롭힘 대화': 2,\n",
    "    '기타 괴롭힘 대화': 3,\n",
    "    '일반 대화':4\n",
    "}\n",
    "train['label_encoded'] = train['class'].map(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7bdc592b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['conversation'] = train['conversation'].apply(clean_text)\n",
    "Test['text'] = Test['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b764f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[['conversation','label_encoded']]\n",
    "train = train.rename(columns = {'label_encoded':'class'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05cc2a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#불용어\n",
    "stopwords = [\n",
    "        '이', '있', '하', '것', '들', '그', '되', '수', '이', '보', '않', '없', '나', '사람', '주', '아니',\n",
    "        '등', '같', '우리', '때', '년', '가', '한', '지', '대하', '오', '말', '일', '그렇', '위하',\n",
    "        '때문', '그것', '두', '말하', '알', '그러나', '받', '못하', '일', '그런', '또', '문제', '더', '사회',\n",
    "        '많', '그리고', '좋', '크', '따르', '중', '나오', '가지', '씨', '시키', '만들', '지금', '생각하',\n",
    "        '그러', '속', '하나', '집', '살', '모르', '적', '월', '데', '자신', '안', '어떤', '내', '내', '경우',\n",
    "        '명', '생각', '시간', '그녀', '다시', '이런', '앞', '보이', '번', '나', '다른', '어떻', '여자', '개',\n",
    "        '전', '들', '사실', '이렇', '점', '싶', '말', '정도', '좀', '원', '잘', '통하', '소리', '놓'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aafba65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4906/4906 [00:03<00:00, 1346.15it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = to_categorical(np.array(train['class']))\n",
    "\n",
    "conversation = list(train['conversation'])\n",
    "\n",
    "mecab = Mecab()\n",
    "for i in tqdm(range(len(conversation))):\n",
    "    temp_x = []\n",
    "    temp_x = mecab.morphs(conversation[i])#토큰화\n",
    "    temp_x = [word for word in temp_x if not word in stopwords]\n",
    "    temp_x = [word for word in temp_x if len(word)>1]\n",
    "    X_train.append(temp_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "408a9b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 1526.07it/s]\n"
     ]
    }
   ],
   "source": [
    "test = []\n",
    "\n",
    "text = list(Test['text'])\n",
    "\n",
    "for i in tqdm(range(len(text))):\n",
    "    temp_x = []\n",
    "    temp_x = mecab.morphs(text[i])#토큰화\n",
    "    temp_x = [word for word in temp_x if not word in stopwords]\n",
    "    temp_x = [word for word in temp_x if len(word)>1]\n",
    "    test.append(temp_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "374e412d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "16f104f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cnt = len(tokenizer.word_index) #단어의 수\n",
    "vocab_size = total_cnt+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "62f67229",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = vocab_size)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "test = tokenizer.texts_to_sequences(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7f298dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train,maxlen=300)\n",
    "test = pad_sequences(test,maxlen=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "166ed69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(Layer):\n",
    "    def __init__(self, embedding_dim, num_heads=8):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.embedding_dim = embedding_dim # d_model\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        assert embedding_dim % self.num_heads == 0\n",
    "\n",
    "        self.projection_dim = embedding_dim // num_heads\n",
    "        self.query_dense = Dense(embedding_dim)\n",
    "        self.key_dense = Dense(embedding_dim)\n",
    "        self.value_dense = Dense(embedding_dim)\n",
    "        self.dense = Dense(embedding_dim)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'embedding_dim' : self.embedding_dim,\n",
    "            'num_heads' : self.num_heads,\n",
    "            \n",
    "            'projection_dim' : self.projection_dim,\n",
    "            'query_dense' : self.query_dense,\n",
    "            'key_dense' : self.key_dense,\n",
    "            'value_dense' : self.value_dense,\n",
    "            'dense' : self.dense\n",
    "        })\n",
    "\n",
    "    def scaled_dot_product_attention(self, query, key, value):\n",
    "        matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "        depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        logits = matmul_qk / tf.math.sqrt(depth)\n",
    "        attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "        output = tf.matmul(attention_weights, value)\n",
    "        return output, attention_weights\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "\n",
    "        # (batch_size, seq_len, embedding_dim)\n",
    "        query = self.query_dense(inputs)\n",
    "        key = self.key_dense(inputs)\n",
    "        value = self.value_dense(inputs)\n",
    "\n",
    "        # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        query = self.split_heads(query, batch_size)  \n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        scaled_attention, _ = self.scaled_dot_product_attention(query, key, value)\n",
    "        # (batch_size, seq_len, num_heads, projection_dim)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  \n",
    "\n",
    "        # (batch_size, seq_len, embedding_dim)\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.embedding_dim))\n",
    "        outputs = self.dense(concat_attention)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0518074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(Layer):\n",
    "    def __init__(self, embedding_dim, num_heads, dff, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadAttention(embedding_dim, num_heads)\n",
    "        self.ffn = Sequential(\n",
    "            [Dense(dff, activation=\"relu\"),\n",
    "             Dense(embedding_dim),]\n",
    "        )\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'att' : self.att,\n",
    "            'ffn' : self.ffn,\n",
    "            'layernorm1' : self.layernorm1,\n",
    "            'layernorm2' : self.layernorm2,\n",
    "            'dropout1' : self.dropout1,\n",
    "            'dropout2' : self.dropout2\n",
    "        })\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1ffa5f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(Layer):\n",
    "    def __init__(self, max_len, vocab_size, embedding_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = Embedding(vocab_size, embedding_dim)\n",
    "        self.pos_emb = Embedding(max_len, embedding_dim)\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'token_emb' : self.token_emb,\n",
    "            'pos_emb' : self.pos_emb,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self, x):\n",
    "        max_len = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=max_len, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "57c867e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 300\n",
    "embedding_dim = 32\n",
    "num_heads = 4\n",
    "dff = 32\n",
    "\n",
    "inputs = Input(shape=(max_len,))\n",
    "embedding_layer = TokenAndPositionEmbedding(max_len, vocab_size, embedding_dim)\n",
    "x = embedding_layer(inputs)\n",
    "transformer_block = TransformerBlock(embedding_dim, num_heads, dff)\n",
    "x = transformer_block(x)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(8, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "outputs = Dense(5, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fef27b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "class F1ScoreCallback(Callback):\n",
    "    def __init__(self, validation_data):\n",
    "        super().__init__()\n",
    "        self.validation_data = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_predict = (np.asarray(self.model.predict(self.validation_data[0]))).round()\n",
    "        val_targ = self.validation_data[1]\n",
    "        _val_f1 = f1_score(val_targ, val_predict, average='macro')\n",
    "        print(f' — val_f1: {_val_f1:.4f}')\n",
    "        logs['val_f1'] = _val_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ca518649",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c1b8053a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "99/99 [==============================] - 3s 17ms/step - loss: 0.0458 - accuracy: 0.9863 - val_loss: 1.2917 - val_accuracy: 0.8357\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.83567, saving model to aiffel/aiffel/dktc/tf_chkpoint.ckpt\n",
      " — val_f1: 0.8364\n",
      "Epoch 2/30\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.0344 - accuracy: 0.9869 - val_loss: 1.3391 - val_accuracy: 0.8357\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.83567\n",
      " — val_f1: 0.8371\n",
      "Epoch 3/30\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.0225 - accuracy: 0.9892 - val_loss: 1.3901 - val_accuracy: 0.8357\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.83567\n",
      " — val_f1: 0.8384\n",
      "Epoch 4/30\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.0292 - accuracy: 0.9879 - val_loss: 1.5580 - val_accuracy: 0.8293\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.83567\n",
      " — val_f1: 0.8330\n",
      "Epoch 5/30\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.0364 - accuracy: 0.9866 - val_loss: 1.7675 - val_accuracy: 0.8115\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.83567\n",
      " — val_f1: 0.8092\n",
      "Epoch 6/30\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.0381 - accuracy: 0.9844 - val_loss: 1.7465 - val_accuracy: 0.8166\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.83567\n",
      " — val_f1: 0.8195\n",
      "Epoch 7/30\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.0297 - accuracy: 0.9892 - val_loss: 1.4546 - val_accuracy: 0.8408\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.83567 to 0.84076, saving model to aiffel/aiffel/dktc/tf_chkpoint.ckpt\n",
      " — val_f1: 0.8426\n",
      "Epoch 8/30\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.0192 - accuracy: 0.9911 - val_loss: 1.5007 - val_accuracy: 0.8420\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.84076 to 0.84204, saving model to aiffel/aiffel/dktc/tf_chkpoint.ckpt\n",
      " — val_f1: 0.8430\n",
      "Epoch 9/30\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.0235 - accuracy: 0.9895 - val_loss: 1.5722 - val_accuracy: 0.8408\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.84204\n",
      " — val_f1: 0.8422\n",
      "Epoch 10/30\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.0196 - accuracy: 0.9904 - val_loss: 1.5918 - val_accuracy: 0.8484\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.84204 to 0.84841, saving model to aiffel/aiffel/dktc/tf_chkpoint.ckpt\n",
      " — val_f1: 0.8493\n",
      "Epoch 11/30\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.0187 - accuracy: 0.9895 - val_loss: 1.6255 - val_accuracy: 0.8408\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.84841\n",
      " — val_f1: 0.8421\n",
      "Epoch 12/30\n",
      "99/99 [==============================] - 1s 14ms/step - loss: 0.0264 - accuracy: 0.9882 - val_loss: 2.0479 - val_accuracy: 0.8268\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.84841\n",
      " — val_f1: 0.8270\n",
      "Epoch 13/30\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.0234 - accuracy: 0.9863 - val_loss: 1.7961 - val_accuracy: 0.8344\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.84841\n",
      " — val_f1: 0.8357\n",
      "Epoch 14/30\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.0168 - accuracy: 0.9911 - val_loss: 1.8698 - val_accuracy: 0.8268\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.84841\n",
      " — val_f1: 0.8281\n",
      "Epoch 15/30\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.0223 - accuracy: 0.9869 - val_loss: 1.9866 - val_accuracy: 0.8268\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.84841\n",
      " — val_f1: 0.8289\n",
      "Epoch 16/30\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.0220 - accuracy: 0.9888 - val_loss: 1.9685 - val_accuracy: 0.8369\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.84841\n",
      " — val_f1: 0.8377\n",
      "Epoch 17/30\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.0200 - accuracy: 0.9908 - val_loss: 1.9915 - val_accuracy: 0.8357\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.84841\n",
      " — val_f1: 0.8367\n",
      "Epoch 18/30\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.0405 - accuracy: 0.9860 - val_loss: 2.0727 - val_accuracy: 0.8102\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.84841\n",
      " — val_f1: 0.8112\n",
      "Epoch 19/30\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.0481 - accuracy: 0.9866 - val_loss: 1.6497 - val_accuracy: 0.8280\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.84841\n",
      " — val_f1: 0.8288\n",
      "Epoch 20/30\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.0320 - accuracy: 0.9879 - val_loss: 1.6658 - val_accuracy: 0.8255\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.84841\n",
      " — val_f1: 0.8288\n",
      "Epoch 21/30\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.0192 - accuracy: 0.9904 - val_loss: 1.6158 - val_accuracy: 0.8293\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.84841\n",
      " — val_f1: 0.8311\n",
      "Epoch 22/30\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.0161 - accuracy: 0.9917 - val_loss: 1.7624 - val_accuracy: 0.8217\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.84841\n",
      " — val_f1: 0.8243\n",
      "Epoch 23/30\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.0201 - accuracy: 0.9885 - val_loss: 1.7141 - val_accuracy: 0.8268\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.84841\n",
      " — val_f1: 0.8271\n",
      "Epoch 24/30\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.0225 - accuracy: 0.9882 - val_loss: 2.0334 - val_accuracy: 0.8229\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.84841\n",
      " — val_f1: 0.8250\n",
      "Epoch 25/30\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.0174 - accuracy: 0.9895 - val_loss: 1.8101 - val_accuracy: 0.8318\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.84841\n",
      " — val_f1: 0.8342\n",
      "Epoch 26/30\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.0182 - accuracy: 0.9901 - val_loss: 1.7789 - val_accuracy: 0.8382\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.84841\n",
      " — val_f1: 0.8391\n",
      "Epoch 27/30\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.0151 - accuracy: 0.9908 - val_loss: 1.9432 - val_accuracy: 0.8242\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.84841\n",
      " — val_f1: 0.8259\n",
      "Epoch 28/30\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.0210 - accuracy: 0.9885 - val_loss: 1.9586 - val_accuracy: 0.8255\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.84841\n",
      " — val_f1: 0.8267\n",
      "Epoch 29/30\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.0174 - accuracy: 0.9898 - val_loss: 1.9611 - val_accuracy: 0.8255\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.84841\n",
      " — val_f1: 0.8281\n",
      "Epoch 30/30\n",
      "99/99 [==============================] - 1s 13ms/step - loss: 0.0148 - accuracy: 0.9927 - val_loss: 2.1784 - val_accuracy: 0.8229\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.84841\n",
      " — val_f1: 0.8234\n"
     ]
    }
   ],
   "source": [
    "# 모델 컴파일\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# 체크포인트 콜백\n",
    "ckpt_1 = 'tf_chkpoint.ckpt'\n",
    "path = 'aiffel/aiffel/dktc/'  # 체크포인트 저장 경로를 적절히 설정하세요\n",
    "mc = ModelCheckpoint(filepath=os.path.join(path, ckpt_1), monitor='val_accuracy', save_best_only=True, mode='max', verbose=1, save_weights_only=True)\n",
    "\n",
    "# F1-score 콜백\n",
    "f1_callback = F1ScoreCallback(validation_data=(X_val, y_val))\n",
    "\n",
    "# 모델 훈련\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=30, validation_data=(X_val, y_val), callbacks=[mc, f1_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1b044314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7bc911b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_001</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_002</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_003</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_004</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>t_005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>t_006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>t_007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>t_008</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>t_009</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  file_name  class\n",
       "0     t_000      1\n",
       "1     t_001      2\n",
       "2     t_002      2\n",
       "3     t_003      2\n",
       "4     t_004      3\n",
       "5     t_005      0\n",
       "6     t_006      0\n",
       "7     t_007      1\n",
       "8     t_008      2\n",
       "9     t_009      1"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(test)\n",
    "\n",
    "submission['class'] = np.argmax(y_pred, axis=-1)\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "63ee88c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('transformer.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc1f309",
   "metadata": {},
   "outputs": [],
   "source": [
    "#에폭3:0.4\n",
    "#에폭 20 :0.626\n",
    "#에폭 30:0.628"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
